//----------------------------------------------------------------------------
// This is autogenerated code by CppSharp.
// Do not edit this file or all your changes will be lost after re-generation.
//----------------------------------------------------------------------------
using System;
using System.Runtime.InteropServices;
using System.Security;

namespace libavutil
{
    public enum AVColorSpace
    {
        AVCOL_SPC_RGB = 0,
        /// <summary>also ITU-R BT1361 / IEC 61966-2-4 xvYCC709 / SMPTE RP177 Annex B</summary>
        AVCOL_SPC_BT709 = 1,
        AVCOL_SPC_UNSPECIFIED = 2,
        AVCOL_SPC_FCC = 4,
        /// <summary>also ITU-R BT601-6 625 / ITU-R BT1358 625 / ITU-R BT1700 625 PAL & SECAM / IEC 61966-2-4 xvYCC601</summary>
        AVCOL_SPC_BT470BG = 5,
        /// <summary>also ITU-R BT601-6 525 / ITU-R BT1358 525 / ITU-R BT1700 NTSC / functionally identical to above</summary>
        AVCOL_SPC_SMPTE170M = 6,
        AVCOL_SPC_SMPTE240M = 7,
        /// <summary>Used by Dirac / VC-2 and H.264 FRext, see ITU-T SG16</summary>
        AVCOL_SPC_YCOCG = 8,
        /// <summary>Not part of ABI</summary>
        AVCOL_SPC_NB = 9
    }

    public enum AVColorRange
    {
        AVCOL_RANGE_UNSPECIFIED = 0,
        /// <summary>the normal 219*2^(n-8) "MPEG" YUV ranges</summary>
        AVCOL_RANGE_MPEG = 1,
        /// <summary>the normal 2^n-1 "JPEG" YUV ranges</summary>
        AVCOL_RANGE_JPEG = 2,
        /// <summary>Not part of ABI</summary>
        AVCOL_RANGE_NB = 3
    }

    public enum AVFrameSideDataType
    {
        /// <summary>The data is the AVPanScan struct defined in libavcodec.</summary>
        AV_FRAME_DATA_PANSCAN = 0
    }

    [StructLayout(LayoutKind.Explicit)]
    public unsafe partial struct AVPanScan
    {
    }

    [StructLayout(LayoutKind.Explicit)]
    public unsafe partial struct AVCodecContext
    {
    }

    [StructLayout(LayoutKind.Explicit)]
    public unsafe partial struct AVFrameSideData
    {
        [FieldOffset(0)]
        public AVFrameSideDataType type;

        [FieldOffset(4)]
        public byte* data;

        [FieldOffset(8)]
        public int size;

        [FieldOffset(12)]
        public AVDictionary* metadata;
    }

    /// <summary>
    /// This structure describes decoded (raw) audio or video data.
    /// 
    /// AVFrame must be allocated using av_frame_alloc(). Note that this only
    /// allocates the AVFrame itself, the buffers for the data must be managed
    /// through other means (see below).
    /// AVFrame must be freed with av_frame_free().
    /// 
    /// AVFrame is typically allocated once and then reused multiple times to
    /// hold
    /// different data (e.g. a single AVFrame to hold frames received from a
    /// decoder). In such a case, av_frame_unref() will free any references
    /// held by
    /// the frame and reset it to its original clean state before it
    /// is reused again.
    /// 
    /// The data described by an AVFrame is usually reference counted through
    /// the
    /// AVBuffer API. The underlying buffer references are stored in
    /// AVFrame.buf /
    /// AVFrame.extended_buf. An AVFrame is considered to be reference counted
    /// if at
    /// least one reference is set, i.e. if AVFrame.buf[0] != NULL. In such a
    /// case,
    /// every single data plane must be contained in one of the buffers in
    /// AVFrame.buf or AVFrame.extended_buf.
    /// There may be a single buffer for all the data, or one separate buffer
    /// for
    /// each plane, or anything in between.
    /// 
    /// sizeof(AVFrame) is not a part of the public ABI, so new fields may be
    /// added
    /// to the end with a minor bump.
    /// Similarly fields that are marked as to be only accessed by
    /// av_opt_ptr() can be reordered. This allows 2 forks to add fields
    /// without breaking compatibility with each other.
    /// </summary>
    [StructLayout(LayoutKind.Explicit)]
    public unsafe partial struct AVFrame
    {
        /// <summary>
        /// pointer to the picture/channel planes.
        /// This might be different from the first allocated byte
        /// 
        /// Some decoders access areas outside 0,0 - width,height, please
        /// see avcodec_align_dimensions2(). Some filters and swscale can read
        /// up to 16 bytes beyond the planes, if these filters are to be used,
        /// then 16 extra bytes must be allocated.
        /// </summary>
        [FieldOffset(0)]
        public byte* data_0;

        /// <summary>
        /// pointer to the picture/channel planes.
        /// This might be different from the first allocated byte
        /// 
        /// Some decoders access areas outside 0,0 - width,height, please
        /// see avcodec_align_dimensions2(). Some filters and swscale can read
        /// up to 16 bytes beyond the planes, if these filters are to be used,
        /// then 16 extra bytes must be allocated.
        /// </summary>
        [FieldOffset(4)]
        public byte* data_1;

        /// <summary>
        /// pointer to the picture/channel planes.
        /// This might be different from the first allocated byte
        /// 
        /// Some decoders access areas outside 0,0 - width,height, please
        /// see avcodec_align_dimensions2(). Some filters and swscale can read
        /// up to 16 bytes beyond the planes, if these filters are to be used,
        /// then 16 extra bytes must be allocated.
        /// </summary>
        [FieldOffset(8)]
        public byte* data_2;

        /// <summary>
        /// pointer to the picture/channel planes.
        /// This might be different from the first allocated byte
        /// 
        /// Some decoders access areas outside 0,0 - width,height, please
        /// see avcodec_align_dimensions2(). Some filters and swscale can read
        /// up to 16 bytes beyond the planes, if these filters are to be used,
        /// then 16 extra bytes must be allocated.
        /// </summary>
        [FieldOffset(12)]
        public byte* data_3;

        /// <summary>
        /// pointer to the picture/channel planes.
        /// This might be different from the first allocated byte
        /// 
        /// Some decoders access areas outside 0,0 - width,height, please
        /// see avcodec_align_dimensions2(). Some filters and swscale can read
        /// up to 16 bytes beyond the planes, if these filters are to be used,
        /// then 16 extra bytes must be allocated.
        /// </summary>
        [FieldOffset(16)]
        public byte* data_4;

        /// <summary>
        /// pointer to the picture/channel planes.
        /// This might be different from the first allocated byte
        /// 
        /// Some decoders access areas outside 0,0 - width,height, please
        /// see avcodec_align_dimensions2(). Some filters and swscale can read
        /// up to 16 bytes beyond the planes, if these filters are to be used,
        /// then 16 extra bytes must be allocated.
        /// </summary>
        [FieldOffset(20)]
        public byte* data_5;

        /// <summary>
        /// pointer to the picture/channel planes.
        /// This might be different from the first allocated byte
        /// 
        /// Some decoders access areas outside 0,0 - width,height, please
        /// see avcodec_align_dimensions2(). Some filters and swscale can read
        /// up to 16 bytes beyond the planes, if these filters are to be used,
        /// then 16 extra bytes must be allocated.
        /// </summary>
        [FieldOffset(24)]
        public byte* data_6;

        /// <summary>
        /// pointer to the picture/channel planes.
        /// This might be different from the first allocated byte
        /// 
        /// Some decoders access areas outside 0,0 - width,height, please
        /// see avcodec_align_dimensions2(). Some filters and swscale can read
        /// up to 16 bytes beyond the planes, if these filters are to be used,
        /// then 16 extra bytes must be allocated.
        /// </summary>
        [FieldOffset(28)]
        public byte* data_7;

        /// <summary>
        /// For video, size in bytes of each picture line.
        /// For audio, size in bytes of each plane.
        /// 
        /// For audio, only linesize[0] may be set. For planar audio, each
        /// channel
        /// plane must be the same size.
        /// 
        /// For video the linesizes should be multiplies of the CPUs alignment
        /// preference, this is 16 or 32 for modern desktop CPUs.
        /// Some code requires such alignment other code can be slower without
        /// correct alignment, for yet other it makes no difference.
        /// 
        /// @note The linesize may be larger than the size of usable data --
        /// there
        /// may be extra padding present for performance reasons.
        /// </summary>
        [FieldOffset(32)]
        public fixed int linesize[8];

        /// <summary>
        /// pointers to the data planes/channels.
        /// 
        /// For video, this should simply point to data[].
        /// 
        /// For planar audio, each channel has a separate data pointer, and
        /// linesize[0] contains the size of each channel buffer.
        /// For packed audio, there is just one data pointer, and linesize[0]
        /// contains the total size of the buffer for all channels.
        /// 
        /// Note: Both data and extended_data should always be set in a valid
        /// frame,
        /// but for planar audio with more channels that can fit in data,
        /// extended_data must be used in order to access all channels.
        /// </summary>
        [FieldOffset(64)]
        public byte* extended_data;

        /// <summary>
        /// width and height of the video frame
        /// </summary>
        [FieldOffset(68)]
        public int width;

        /// <summary>
        /// width and height of the video frame
        /// </summary>
        [FieldOffset(72)]
        public int height;

        /// <summary>
        /// number of audio samples (per channel) described by this frame
        /// </summary>
        [FieldOffset(76)]
        public int nb_samples;

        /// <summary>
        /// format of the frame, -1 if unknown or unset
        /// Values correspond to enum AVPixelFormat for video frames,
        /// enum AVSampleFormat for audio)
        /// </summary>
        [FieldOffset(80)]
        public int format;

        /// <summary>
        /// 1 -> keyframe, 0-> not
        /// </summary>
        [FieldOffset(84)]
        public int key_frame;

        /// <summary>
        /// Picture type of the frame.
        /// </summary>
        [FieldOffset(88)]
        public AVPictureType pict_type;

        [FieldOffset(92)]
        public byte* @base_0;

        [FieldOffset(96)]
        public byte* @base_1;

        [FieldOffset(100)]
        public byte* @base_2;

        [FieldOffset(104)]
        public byte* @base_3;

        [FieldOffset(108)]
        public byte* @base_4;

        [FieldOffset(112)]
        public byte* @base_5;

        [FieldOffset(116)]
        public byte* @base_6;

        [FieldOffset(120)]
        public byte* @base_7;

        /// <summary>
        /// Sample aspect ratio for the video frame, 0/1 if
        /// unknown/unspecified.
        /// </summary>
        [FieldOffset(124)]
        public AVRational* sample_aspect_ratio;

        /// <summary>
        /// Presentation timestamp in time_base units (time when frame should
        /// be shown to user).
        /// </summary>
        [FieldOffset(136)]
        public long pts;

        /// <summary>
        /// PTS copied from the AVPacket that was decoded to produce this
        /// frame.
        /// </summary>
        [FieldOffset(144)]
        public long pkt_pts;

        /// <summary>
        /// DTS copied from the AVPacket that triggered returning this frame.
        /// (if frame threading isnt used)
        /// This is also the Presentation time of this AVFrame calculated from
        /// only AVPacket.dts values without pts values.
        /// </summary>
        [FieldOffset(152)]
        public long pkt_dts;

        /// <summary>
        /// picture number in bitstream order
        /// </summary>
        [FieldOffset(160)]
        public int coded_picture_number;

        /// <summary>
        /// picture number in display order
        /// </summary>
        [FieldOffset(164)]
        public int display_picture_number;

        /// <summary>
        /// quality (between 1 (good) and FF_LAMBDA_MAX (bad))
        /// </summary>
        [FieldOffset(168)]
        public int quality;

        [FieldOffset(172)]
        public int reference;

        /// <summary>
        /// QP table
        /// </summary>
        [FieldOffset(176)]
        public sbyte* qscale_table;

        /// <summary>
        /// QP store stride
        /// </summary>
        [FieldOffset(180)]
        public int qstride;

        [FieldOffset(184)]
        public int qscale_type;

        /// <summary>
        /// mbskip_table[mb]>=1 if MB didn't change
        /// stride= mb_width = (width+15)>>4
        /// </summary>
        [FieldOffset(188)]
        public byte* mbskip_table;

        /// <summary>
        /// motion vector table
        /// @code
        /// example:
        /// int mv_sample_log2= 4 - motion_subsample_log2;
        /// int mb_width= (width+15)>>4;
        /// int mv_stride= (mb_width << mv_sample_log2) + 1;
        /// motion_val[direction][x + y*mv_stride][0->mv_x, 1->mv_y];
        /// @endcode
        /// </summary>
        [FieldOffset(192)]
        public fixed short motion_val_0[2];

        /// <summary>
        /// motion vector table
        /// @code
        /// example:
        /// int mv_sample_log2= 4 - motion_subsample_log2;
        /// int mb_width= (width+15)>>4;
        /// int mv_stride= (mb_width << mv_sample_log2) + 1;
        /// motion_val[direction][x + y*mv_stride][0->mv_x, 1->mv_y];
        /// @endcode
        /// </summary>
        [FieldOffset(196)]
        public fixed short motion_val_1[2];

        /// <summary>
        /// macroblock type table
        /// mb_type_base + mb_width + 2
        /// </summary>
        [FieldOffset(200)]
        public uint* mb_type;

        /// <summary>
        /// DCT coefficients
        /// </summary>
        [FieldOffset(204)]
        public short* dct_coeff;

        /// <summary>
        /// motion reference frame index
        /// the order in which these are stored can depend on the codec.
        /// </summary>
        [FieldOffset(208)]
        public sbyte* ref_index_0;

        /// <summary>
        /// motion reference frame index
        /// the order in which these are stored can depend on the codec.
        /// </summary>
        [FieldOffset(212)]
        public sbyte* ref_index_1;

        /// <summary>
        /// for some private data of the user
        /// </summary>
        [FieldOffset(216)]
        public global::System.IntPtr opaque;

        /// <summary>
        /// error
        /// </summary>
        [FieldOffset(224)]
        public fixed ulong error[8];

        [FieldOffset(288)]
        public int type;

        /// <summary>
        /// When decoding, this signals how much the picture must be delayed.
        /// extra_delay = repeat_pict / (2*fps)
        /// </summary>
        [FieldOffset(292)]
        public int repeat_pict;

        /// <summary>
        /// The content of the picture is interlaced.
        /// </summary>
        [FieldOffset(296)]
        public int interlaced_frame;

        /// <summary>
        /// If the content is interlaced, is top field displayed first.
        /// </summary>
        [FieldOffset(300)]
        public int top_field_first;

        /// <summary>
        /// Tell user application that palette has changed from previous frame.
        /// </summary>
        [FieldOffset(304)]
        public int palette_has_changed;

        [FieldOffset(308)]
        public int buffer_hints;

        /// <summary>
        /// Pan scan.
        /// </summary>
        [FieldOffset(312)]
        public AVPanScan* pan_scan;

        /// <summary>
        /// reordered opaque 64bit (generally an integer or a double precision
        /// float
        /// PTS but can be anything).
        /// The user sets AVCodecContext.reordered_opaque to represent the
        /// input at
        /// that time,
        /// the decoder reorders values as needed and sets
        /// AVFrame.reordered_opaque
        /// to exactly one of the values provided by the user through
        /// AVCodecContext.reordered_opaque
        /// @deprecated in favor of pkt_pts
        /// </summary>
        [FieldOffset(320)]
        public long reordered_opaque;

        [FieldOffset(328)]
        public global::System.IntPtr hwaccel_picture_private;

        [FieldOffset(332)]
        public AVCodecContext* owner;

        [FieldOffset(336)]
        public global::System.IntPtr thread_opaque;

        /// <summary>
        /// log2 of the size of the block which a single vector in motion_val
        /// represents:
        /// (4->16x16, 3->8x8, 2-> 4x4, 1-> 2x2)
        /// </summary>
        [FieldOffset(340)]
        public byte motion_subsample_log2;

        /// <summary>
        /// Sample rate of the audio data.
        /// </summary>
        [FieldOffset(344)]
        public int sample_rate;

        /// <summary>
        /// Channel layout of the audio data.
        /// </summary>
        [FieldOffset(352)]
        public ulong channel_layout;

        /// <summary>
        /// AVBuffer references backing the data for this frame. If all
        /// elements of
        /// this array are NULL, then this frame is not reference counted.
        /// 
        /// There may be at most one AVBuffer per data plane, so for video this
        /// array
        /// always contains all the references. For planar audio with more than
        /// AV_NUM_DATA_POINTERS channels, there may be more buffers than can
        /// fit in
        /// this array. Then the extra AVBufferRef pointers are stored in the
        /// extended_buf array.
        /// </summary>
        [FieldOffset(360)]
        public AVBufferRef* buf_0;

        /// <summary>
        /// AVBuffer references backing the data for this frame. If all
        /// elements of
        /// this array are NULL, then this frame is not reference counted.
        /// 
        /// There may be at most one AVBuffer per data plane, so for video this
        /// array
        /// always contains all the references. For planar audio with more than
        /// AV_NUM_DATA_POINTERS channels, there may be more buffers than can
        /// fit in
        /// this array. Then the extra AVBufferRef pointers are stored in the
        /// extended_buf array.
        /// </summary>
        [FieldOffset(364)]
        public AVBufferRef* buf_1;

        /// <summary>
        /// AVBuffer references backing the data for this frame. If all
        /// elements of
        /// this array are NULL, then this frame is not reference counted.
        /// 
        /// There may be at most one AVBuffer per data plane, so for video this
        /// array
        /// always contains all the references. For planar audio with more than
        /// AV_NUM_DATA_POINTERS channels, there may be more buffers than can
        /// fit in
        /// this array. Then the extra AVBufferRef pointers are stored in the
        /// extended_buf array.
        /// </summary>
        [FieldOffset(368)]
        public AVBufferRef* buf_2;

        /// <summary>
        /// AVBuffer references backing the data for this frame. If all
        /// elements of
        /// this array are NULL, then this frame is not reference counted.
        /// 
        /// There may be at most one AVBuffer per data plane, so for video this
        /// array
        /// always contains all the references. For planar audio with more than
        /// AV_NUM_DATA_POINTERS channels, there may be more buffers than can
        /// fit in
        /// this array. Then the extra AVBufferRef pointers are stored in the
        /// extended_buf array.
        /// </summary>
        [FieldOffset(372)]
        public AVBufferRef* buf_3;

        /// <summary>
        /// AVBuffer references backing the data for this frame. If all
        /// elements of
        /// this array are NULL, then this frame is not reference counted.
        /// 
        /// There may be at most one AVBuffer per data plane, so for video this
        /// array
        /// always contains all the references. For planar audio with more than
        /// AV_NUM_DATA_POINTERS channels, there may be more buffers than can
        /// fit in
        /// this array. Then the extra AVBufferRef pointers are stored in the
        /// extended_buf array.
        /// </summary>
        [FieldOffset(376)]
        public AVBufferRef* buf_4;

        /// <summary>
        /// AVBuffer references backing the data for this frame. If all
        /// elements of
        /// this array are NULL, then this frame is not reference counted.
        /// 
        /// There may be at most one AVBuffer per data plane, so for video this
        /// array
        /// always contains all the references. For planar audio with more than
        /// AV_NUM_DATA_POINTERS channels, there may be more buffers than can
        /// fit in
        /// this array. Then the extra AVBufferRef pointers are stored in the
        /// extended_buf array.
        /// </summary>
        [FieldOffset(380)]
        public AVBufferRef* buf_5;

        /// <summary>
        /// AVBuffer references backing the data for this frame. If all
        /// elements of
        /// this array are NULL, then this frame is not reference counted.
        /// 
        /// There may be at most one AVBuffer per data plane, so for video this
        /// array
        /// always contains all the references. For planar audio with more than
        /// AV_NUM_DATA_POINTERS channels, there may be more buffers than can
        /// fit in
        /// this array. Then the extra AVBufferRef pointers are stored in the
        /// extended_buf array.
        /// </summary>
        [FieldOffset(384)]
        public AVBufferRef* buf_6;

        /// <summary>
        /// AVBuffer references backing the data for this frame. If all
        /// elements of
        /// this array are NULL, then this frame is not reference counted.
        /// 
        /// There may be at most one AVBuffer per data plane, so for video this
        /// array
        /// always contains all the references. For planar audio with more than
        /// AV_NUM_DATA_POINTERS channels, there may be more buffers than can
        /// fit in
        /// this array. Then the extra AVBufferRef pointers are stored in the
        /// extended_buf array.
        /// </summary>
        [FieldOffset(388)]
        public AVBufferRef* buf_7;

        /// <summary>
        /// For planar audio which requires more than AV_NUM_DATA_POINTERS
        /// AVBufferRef pointers, this array will hold all the references which
        /// cannot fit into AVFrame.buf.
        /// 
        /// Note that this is different from AVFrame.extended_data, which
        /// always
        /// contains all the pointers. This array only contains the extra
        /// pointers,
        /// which cannot fit into AVFrame.buf.
        /// 
        /// This array is always allocated using av_malloc() by whoever
        /// constructs
        /// the frame. It is freed in av_frame_unref().
        /// </summary>
        [FieldOffset(392)]
        public AVBufferRef* extended_buf;

        /// <summary>
        /// Number of elements in extended_buf.
        /// </summary>
        [FieldOffset(396)]
        public int nb_extended_buf;

        [FieldOffset(400)]
        public AVFrameSideData* side_data;

        [FieldOffset(404)]
        public int nb_side_data;

        /// <summary>
        /// frame timestamp estimated using various heuristics, in stream time
        /// base
        /// Code outside libavcodec should access this field using:
        /// av_frame_get_best_effort_timestamp(frame)
        /// - encoding: unused
        /// - decoding: set by libavcodec, read by user.
        /// </summary>
        [FieldOffset(408)]
        public long best_effort_timestamp;

        /// <summary>
        /// reordered pos from the last AVPacket that has been input into the
        /// decoder
        /// Code outside libavcodec should access this field using:
        /// av_frame_get_pkt_pos(frame)
        /// - encoding: unused
        /// - decoding: Read by user.
        /// </summary>
        [FieldOffset(416)]
        public long pkt_pos;

        /// <summary>
        /// duration of the corresponding packet, expressed in
        /// AVStream->time_base units, 0 if unknown.
        /// Code outside libavcodec should access this field using:
        /// av_frame_get_pkt_duration(frame)
        /// - encoding: unused
        /// - decoding: Read by user.
        /// </summary>
        [FieldOffset(424)]
        public long pkt_duration;

        /// <summary>
        /// metadata.
        /// Code outside libavcodec should access this field using:
        /// av_frame_get_metadata(frame)
        /// - encoding: Set by user.
        /// - decoding: Set by libavcodec.
        /// </summary>
        [FieldOffset(432)]
        public AVDictionary* metadata;

        /// <summary>
        /// decode error flags of the frame, set to a combination of
        /// FF_DECODE_ERROR_xxx flags if the decoder produced a frame, but
        /// there
        /// were errors during the decoding.
        /// Code outside libavcodec should access this field using:
        /// av_frame_get_decode_error_flags(frame)
        /// - encoding: unused
        /// - decoding: set by libavcodec, read by user.
        /// </summary>
        [FieldOffset(436)]
        public int decode_error_flags;

        /// <summary>
        /// number of audio channels, only used for audio.
        /// Code outside libavcodec should access this field using:
        /// av_frame_get_channels(frame)
        /// - encoding: unused
        /// - decoding: Read by user.
        /// </summary>
        [FieldOffset(440)]
        public int channels;

        /// <summary>
        /// size of the corresponding packet containing the compressed
        /// frame. It must be accessed using av_frame_get_pkt_size() and
        /// av_frame_set_pkt_size().
        /// It is set to a negative value if unknown.
        /// - encoding: unused
        /// - decoding: set by libavcodec, read by user.
        /// </summary>
        [FieldOffset(444)]
        public int pkt_size;

        /// <summary>
        /// YUV colorspace type.
        /// It must be accessed using av_frame_get_colorspace() and
        /// av_frame_set_colorspace().
        /// - encoding: Set by user
        /// - decoding: Set by libavcodec
        /// </summary>
        [FieldOffset(448)]
        public AVColorSpace colorspace;

        /// <summary>
        /// MPEG vs JPEG YUV range.
        /// It must be accessed using av_frame_get_color_range() and
        /// av_frame_set_color_range().
        /// - encoding: Set by user
        /// - decoding: Set by libavcodec
        /// </summary>
        [FieldOffset(452)]
        public AVColorRange color_range;

        /// <summary>
        /// Not to be accessed directly from outside libavutil
        /// </summary>
        [FieldOffset(456)]
        public AVBufferRef* qp_table_buf;
    }

    public unsafe partial class libavutil
    {
        /// <summary>
        /// Accessors for some AVFrame fields.
        /// The position of these field in the structure is not part of the ABI,
        /// they should not be accessed directly outside libavcodec.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_best_effort_timestamp")]
        internal static extern long av_frame_get_best_effort_timestamp(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_best_effort_timestamp")]
        internal static extern void av_frame_set_best_effort_timestamp(AVFrame* frame, long val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_pkt_duration")]
        internal static extern long av_frame_get_pkt_duration(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_pkt_duration")]
        internal static extern void av_frame_set_pkt_duration(AVFrame* frame, long val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_pkt_pos")]
        internal static extern long av_frame_get_pkt_pos(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_pkt_pos")]
        internal static extern void av_frame_set_pkt_pos(AVFrame* frame, long val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_channel_layout")]
        internal static extern long av_frame_get_channel_layout(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_channel_layout")]
        internal static extern void av_frame_set_channel_layout(AVFrame* frame, long val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_channels")]
        internal static extern int av_frame_get_channels(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_channels")]
        internal static extern void av_frame_set_channels(AVFrame* frame, int val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_sample_rate")]
        internal static extern int av_frame_get_sample_rate(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_sample_rate")]
        internal static extern void av_frame_set_sample_rate(AVFrame* frame, int val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_metadata")]
        internal static extern AVDictionary* av_frame_get_metadata(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_metadata")]
        internal static extern void av_frame_set_metadata(AVFrame* frame, AVDictionary* val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_decode_error_flags")]
        internal static extern int av_frame_get_decode_error_flags(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_decode_error_flags")]
        internal static extern void av_frame_set_decode_error_flags(AVFrame* frame, int val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_pkt_size")]
        internal static extern int av_frame_get_pkt_size(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_pkt_size")]
        internal static extern void av_frame_set_pkt_size(AVFrame* frame, int val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="avpriv_frame_get_metadatap")]
        internal static extern AVDictionary* avpriv_frame_get_metadatap(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_qp_table")]
        internal static extern sbyte* av_frame_get_qp_table(AVFrame* f, int* stride, int* type);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_qp_table")]
        internal static extern int av_frame_set_qp_table(AVFrame* f, AVBufferRef* buf, int stride, int type);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_colorspace")]
        internal static extern AVColorSpace av_frame_get_colorspace(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_colorspace")]
        internal static extern void av_frame_set_colorspace(AVFrame* frame, AVColorSpace val);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_color_range")]
        internal static extern AVColorRange av_frame_get_color_range(AVFrame* frame);

        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_set_color_range")]
        internal static extern void av_frame_set_color_range(AVFrame* frame, AVColorRange val);

        /// <summary>
        /// Get the name of a colorspace.
        /// @return a static string identifying the colorspace; can be NULL.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_get_colorspace_name")]
        internal static extern global::System.IntPtr av_get_colorspace_name(AVColorSpace val);

        /// <summary>
        /// Allocate an AVFrame and set its fields to default values.  The
        /// resulting
        /// struct must be freed using av_frame_free().
        /// 
        /// @return An AVFrame filled with default values or NULL on failure.
        /// 
        /// @note this only allocates the AVFrame itself, not the data buffers.
        /// Those
        /// must be allocated through other means, e.g. with av_frame_get_buffer()
        /// or
        /// manually.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_alloc")]
        internal static extern AVFrame* av_frame_alloc();

        /// <summary>
        /// Free the frame and any dynamically allocated objects in it,
        /// e.g. extended_data. If the frame is reference counted, it will be
        /// unreferenced first.
        /// 
        /// @param frame frame to be freed. The pointer will be set to NULL.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_free")]
        internal static extern void av_frame_free(AVFrame* frame);

        /// <summary>
        /// Setup a new reference to the data described by a given frame.
        /// 
        /// Copy frame properties from src to dst and create a new reference for
        /// each
        /// AVBufferRef from src.
        /// 
        /// If src is not reference counted, new buffers are allocated and the data
        /// is
        /// copied.
        /// 
        /// @return 0 on success, a negative AVERROR on error
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_ref")]
        internal static extern int av_frame_ref(AVFrame* dst, AVFrame* src);

        /// <summary>
        /// Create a new frame that references the same data as src.
        /// 
        /// This is a shortcut for av_frame_alloc()+av_frame_ref().
        /// 
        /// @return newly created AVFrame on success, NULL on error.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_clone")]
        internal static extern AVFrame* av_frame_clone(AVFrame* src);

        /// <summary>
        /// Unreference all the buffers referenced by frame and reset the frame
        /// fields.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_unref")]
        internal static extern void av_frame_unref(AVFrame* frame);

        /// <summary>
        /// Move everythnig contained in src to dst and reset src.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_move_ref")]
        internal static extern void av_frame_move_ref(AVFrame* dst, AVFrame* src);

        /// <summary>
        /// Allocate new buffer(s) for audio or video data.
        /// 
        /// The following fields must be set on frame before calling this function:
        /// - format (pixel format for video, sample format for audio)
        /// - width and height for video
        /// - nb_samples and channel_layout for audio
        /// 
        /// This function will fill AVFrame.data and AVFrame.buf arrays and, if
        /// necessary, allocate and fill AVFrame.extended_data and
        /// AVFrame.extended_buf.
        /// For planar formats, one buffer will be allocated for each plane.
        /// 
        /// @param frame frame in which to store the new buffers.
        /// @param align required buffer size alignment
        /// 
        /// @return 0 on success, a negative AVERROR on error.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_buffer")]
        internal static extern int av_frame_get_buffer(AVFrame* frame, int align);

        /// <summary>
        /// Check if the frame data is writable.
        /// 
        /// @return A positive value if the frame data is writable (which is true
        /// if and
        /// only if each of the underlying buffers has only one reference, namely
        /// the one
        /// stored in this frame). Return 0 otherwise.
        /// 
        /// If 1 is returned the answer is valid until av_buffer_ref() is called on
        /// any
        /// of the underlying AVBufferRefs (e.g. through av_frame_ref() or
        /// directly).
        /// 
        /// @see av_frame_make_writable(), av_buffer_is_writable()
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_is_writable")]
        internal static extern int av_frame_is_writable(AVFrame* frame);

        /// <summary>
        /// Ensure that the frame data is writable, avoiding data copy if possible.
        /// 
        /// Do nothing if the frame is writable, allocate new buffers and copy the
        /// data
        /// if it is not.
        /// 
        /// @return 0 on success, a negative AVERROR on error.
        /// 
        /// @see av_frame_is_writable(), av_buffer_is_writable(),
        /// av_buffer_make_writable()
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_make_writable")]
        internal static extern int av_frame_make_writable(AVFrame* frame);

        /// <summary>
        /// Copy only "metadata" fields from src to dst.
        /// 
        /// Metadata for the purpose of this function are those fields that do not
        /// affect
        /// the data layout in the buffers.  E.g. pts, sample rate (for audio) or
        /// sample
        /// aspect ratio (for video), but not width/height or channel layout.
        /// Side data is also copied.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_copy_props")]
        internal static extern int av_frame_copy_props(AVFrame* dst, AVFrame* src);

        /// <summary>
        /// Get the buffer reference a given data plane is stored in.
        /// 
        /// @param plane index of the data plane of interest in
        /// frame->extended_data.
        /// 
        /// @return the buffer reference that contains the plane or NULL if the
        /// input
        /// frame is not valid.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_plane_buffer")]
        internal static extern AVBufferRef* av_frame_get_plane_buffer(AVFrame* frame, int plane);

        /// <summary>
        /// Add a new side data to a frame.
        /// 
        /// @param frame a frame to which the side data should be added
        /// @param type type of the added side data
        /// @param size size of the side data
        /// 
        /// @return newly added side data on success, NULL on error
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_new_side_data")]
        internal static extern AVFrameSideData* av_frame_new_side_data(AVFrame* frame, AVFrameSideDataType type, int size);

        /// <summary>
        /// @return a pointer to the side data of a given type on success, NULL if
        /// there
        /// is no side data with such type in this frame.
        /// </summary>
        [SuppressUnmanagedCodeSecurity]
        [DllImport("avutil-if-52.dll", CallingConvention = global::System.Runtime.InteropServices.CallingConvention.Cdecl,
            EntryPoint="av_frame_get_side_data")]
        internal static extern AVFrameSideData* av_frame_get_side_data(AVFrame* frame, AVFrameSideDataType type);
    }
}
